<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-07-17T12:57:30+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Carmen Amo Alonso</title><subtitle>Carmen Amo Alonso</subtitle><entry><title type="html">Linearly Controlled Language Generation with Performative Guarantees</title><link href="http://localhost:4000/publications/2024/05/01/LiSeCo.html" rel="alternate" type="text/html" title="Linearly Controlled Language Generation with Performative Guarantees" /><published>2024-05-01T00:00:00+02:00</published><updated>2024-05-01T00:00:00+02:00</updated><id>http://localhost:4000/publications/2024/05/01/LiSeCo</id><content type="html" xml:base="http://localhost:4000/publications/2024/05/01/LiSeCo.html">&lt;p&gt;The increasing prevalence of Large Language Models (LMs) in critical applications highlights the need for controlled language generation strategies that are not only computationally efficient but that also enjoy performance guarantees. To achieve this, we use a common model of concept semantics as linearly represented in an LM’s latent space. In particular, we take the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model’s hidden activations. This view permits a control-theoretic treatment of text generation in latent space, in which we propose a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings. Crucially, we show that this intervention, which we compute in closed form, is guaranteed (in probability) to steer the output into the allowed region. Finally, we demonstrate on a toxicity avoidance objective that the intervention steers language away from undesired content while maintaining text quality.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">The increasing prevalence of Large Language Models (LMs) in critical applications highlights the need for controlled language generation strategies that are not only computationally efficient but that also enjoy performance guarantees. To achieve this, we use a common model of concept semantics as linearly represented in an LM’s latent space. In particular, we take the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model’s hidden activations. This view permits a control-theoretic treatment of text generation in latent space, in which we propose a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings. Crucially, we show that this intervention, which we compute in closed form, is guaranteed (in probability) to steer the output into the allowed region. Finally, we demonstrate on a toxicity avoidance objective that the intervention steers language away from undesired content while maintaining text quality.</summary></entry><entry><title type="html">Understanding the differences in Foundation Models: Attention, SSMs, and RNNs</title><link href="http://localhost:4000/publications/2024/05/01/DSF.html" rel="alternate" type="text/html" title="Understanding the differences in Foundation Models: Attention, SSMs, and RNNs" /><published>2024-05-01T00:00:00+02:00</published><updated>2024-05-01T00:00:00+02:00</updated><id>http://localhost:4000/publications/2024/05/01/DSF</id><content type="html" xml:base="http://localhost:4000/publications/2024/05/01/DSF.html">&lt;p&gt;Softmax attention is the principle backbone of foundation models for various artificial intelligence applications, yet its quadratic complexity in sequence length can limit its inference throughput in long-context settings. To address this challenge, alternative architectures such as linear attention, State Space Models (SSMs), and Recurrent Neural Networks (RNNs) have been considered as more efficient alternatives. While connections between these approaches exist, such models are commonly developed in isolation and there is a lack of theoretical understanding of the shared principles underpinning these architectures and their subtle differences, greatly influencing performance and scalability. In this paper, we introduce the Dynamical Systems Framework (DSF), which allows a principled investigation of all these architectures in a common representation. Our framework facilitates rigorous comparisons, providing new insights on the distinctive characteristics of each model class. For instance, we compare linear attention and selective SSMs, detailing their differences and conditions under which both are equivalent. We also provide principled comparisons between softmax attention and other model classes, discussing the theoretical conditions under which softmax attention can be approximated. Additionally, we substantiate these new insights with empirical validations and mathematical arguments. This shows the DSF’s potential to guide the systematic development of future more efficient and scalable foundation models.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">Softmax attention is the principle backbone of foundation models for various artificial intelligence applications, yet its quadratic complexity in sequence length can limit its inference throughput in long-context settings. To address this challenge, alternative architectures such as linear attention, State Space Models (SSMs), and Recurrent Neural Networks (RNNs) have been considered as more efficient alternatives. While connections between these approaches exist, such models are commonly developed in isolation and there is a lack of theoretical understanding of the shared principles underpinning these architectures and their subtle differences, greatly influencing performance and scalability. In this paper, we introduce the Dynamical Systems Framework (DSF), which allows a principled investigation of all these architectures in a common representation. Our framework facilitates rigorous comparisons, providing new insights on the distinctive characteristics of each model class. For instance, we compare linear attention and selective SSMs, detailing their differences and conditions under which both are equivalent. We also provide principled comparisons between softmax attention and other model classes, discussing the theoretical conditions under which softmax attention can be approximated. Additionally, we substantiate these new insights with empirical validations and mathematical arguments. This shows the DSF’s potential to guide the systematic development of future more efficient and scalable foundation models.</summary></entry><entry><title type="html">State Space Models as Foundation Models: A Control Theoretic Overview</title><link href="http://localhost:4000/publications/2024/03/01/FM-CDC.html" rel="alternate" type="text/html" title="State Space Models as Foundation Models: A Control Theoretic Overview" /><published>2024-03-01T00:00:00+01:00</published><updated>2024-03-01T00:00:00+01:00</updated><id>http://localhost:4000/publications/2024/03/01/FM-CDC</id><content type="html" xml:base="http://localhost:4000/publications/2024/03/01/FM-CDC.html">&lt;p&gt;In recent years, there has been a growing interest in integrating linear state-space models (SSM) in deep neural network architectures of foundation models. This is exemplified by the recent success of Mamba, showing better performance than the state-of-the-art Transformer architectures in language tasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a latent space in order to learn a compressed representation of the data. The same goal has been pursued by control theorists using SSMs to efficiently model dynamical systems. Therefore, SSMs can be naturally connected to deep sequence modeling, offering the opportunity to create synergies between the corresponding research areas. This paper is intended as a gentle introduction to SSM-based architectures for control theorists and summarizes the latest research developments. It provides a systematic review of the most successful SSM proposals and highlights their main features from a control theoretic perspective. Additionally, we present a comparative analysis of these models, evaluating their performance on a standardized benchmark designed for assessing a model’s efficiency at learning long sequences.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">In recent years, there has been a growing interest in integrating linear state-space models (SSM) in deep neural network architectures of foundation models. This is exemplified by the recent success of Mamba, showing better performance than the state-of-the-art Transformer architectures in language tasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a latent space in order to learn a compressed representation of the data. The same goal has been pursued by control theorists using SSMs to efficiently model dynamical systems. Therefore, SSMs can be naturally connected to deep sequence modeling, offering the opportunity to create synergies between the corresponding research areas. This paper is intended as a gentle introduction to SSM-based architectures for control theorists and summarizes the latest research developments. It provides a systematic review of the most successful SSM proposals and highlights their main features from a control theoretic perspective. Additionally, we present a comparative analysis of these models, evaluating their performance on a standardized benchmark designed for assessing a model’s efficiency at learning long sequences.</summary></entry><entry><title type="html">NARRATE: Versatile Language Architecture for Optimal Control in Robotics</title><link href="http://localhost:4000/publications/2024/02/01/NARRATE.html" rel="alternate" type="text/html" title="NARRATE: Versatile Language Architecture for Optimal Control in Robotics" /><published>2024-02-01T00:00:00+01:00</published><updated>2024-02-01T00:00:00+01:00</updated><id>http://localhost:4000/publications/2024/02/01/NARRATE</id><content type="html" xml:base="http://localhost:4000/publications/2024/02/01/NARRATE.html">&lt;p&gt;The impressive capabilities of Large Language Models (LLMs) have led to various efforts to enable robots to be controlled through natural language instructions, opening exciting possibilities for human-robot interaction The goal is for the motor-control task to be performed accurately, efficiently and safely while also enjoying the flexibility imparted by LLMs to specify and adjust the task through natural language. In this work, we demonstrate how a careful layering of an LLM in combination with a Model Predictive Control (MPC) formulation allows for accurate and flexible robotic control via natural language while taking into consideration safety constraints. In particular, we rely on the LLM to effectively frame constraints and objective functions as mathematical expressions, which are later used in the motor-control module via MPC. The transparency of the optimization formulation allows for interpretability of the task and enables adjustments through human feedback. We demonstrate the validity of our method through extensive experiments on long-horizon reasoning, contact-rich, and multi-object interaction tasks. Our evaluations show that NARRATE outperforms current existing methods on these benchmarks and effectively transfers to the real world on two different embodiments.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">The impressive capabilities of Large Language Models (LLMs) have led to various efforts to enable robots to be controlled through natural language instructions, opening exciting possibilities for human-robot interaction The goal is for the motor-control task to be performed accurately, efficiently and safely while also enjoying the flexibility imparted by LLMs to specify and adjust the task through natural language. In this work, we demonstrate how a careful layering of an LLM in combination with a Model Predictive Control (MPC) formulation allows for accurate and flexible robotic control via natural language while taking into consideration safety constraints. In particular, we rely on the LLM to effectively frame constraints and objective functions as mathematical expressions, which are later used in the motor-control module via MPC. The transparency of the optimization formulation allows for interpretability of the task and enables adjustments through human feedback. We demonstrate the validity of our method through extensive experiments on long-horizon reasoning, contact-rich, and multi-object interaction tasks. Our evaluations show that NARRATE outperforms current existing methods on these benchmarks and effectively transfers to the real world on two different embodiments.</summary></entry><entry><title type="html">Distributed and Localized Model Predictive Control</title><link href="http://localhost:4000/publications/2023/06/01/DLMPC-thesis.html" rel="alternate" type="text/html" title="Distributed and Localized Model Predictive Control" /><published>2023-06-01T00:00:00+02:00</published><updated>2023-06-01T00:00:00+02:00</updated><id>http://localhost:4000/publications/2023/06/01/DLMPC-thesis</id><content type="html" xml:base="http://localhost:4000/publications/2023/06/01/DLMPC-thesis.html">&lt;p&gt;The increasing presence of large-scale distributed systems highlights the need for scalable control strategies where only local communication is required. Moreover, in safety-critical systems it is imperative that such control strategies handle constraints in the presence of disturbances and enjoy theoretical and performance guarantees. In response to this need, we present the Distributed and Localized Model Predictive Control (DLMPC) algorithm for large-scale linear systems. DLMPC is a distributed closed-loop model predictive control (MPC) scheme wherein only local state and model information needs to be exchanged between subsystems for the computation and implementation of control actions. The resulting distributed algorithms tackle various types of additive disturbances and enjoy recursive feasibility and asymptotic stability guarantees that introduce minimal conservatism and can be computed in an offline fashion without adding to the computational burden. We also provide analysis and guarantees on the global performance of DLMPC, and demonstrate that in cases where the underlying topology of the system is sparse (as is the case in most large-scale networks), the inclusion of local communication constraints does not result in a suboptimal solution. Moreover, we show that when no noise is present, this algorithm can be extended to the purely data-driven case where all previous guarantees hold and the need for a model is fully replaced by past-trajectory data. We show that the amount of data needed for our synthesis problem is independent of the size of the global system. Lastly, we explore the potential of DLMPC for hardware accelerated implementation in GPU by exploiting the fact that the structure of the DLMPC problem captures some of the limitations of GPU computations. In all algorithmic and theoretical results presented in this thesis, only local information exchange is necessary, and computational complexity is independent of the global system size. DLMPC is the first MPC algorithm that allows for the scalable, efficient and data-driven computation and implementation of distributed closed-loop control policies and enjoys theoretical guarantees.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">The increasing presence of large-scale distributed systems highlights the need for scalable control strategies where only local communication is required. Moreover, in safety-critical systems it is imperative that such control strategies handle constraints in the presence of disturbances and enjoy theoretical and performance guarantees. In response to this need, we present the Distributed and Localized Model Predictive Control (DLMPC) algorithm for large-scale linear systems. DLMPC is a distributed closed-loop model predictive control (MPC) scheme wherein only local state and model information needs to be exchanged between subsystems for the computation and implementation of control actions. The resulting distributed algorithms tackle various types of additive disturbances and enjoy recursive feasibility and asymptotic stability guarantees that introduce minimal conservatism and can be computed in an offline fashion without adding to the computational burden. We also provide analysis and guarantees on the global performance of DLMPC, and demonstrate that in cases where the underlying topology of the system is sparse (as is the case in most large-scale networks), the inclusion of local communication constraints does not result in a suboptimal solution. Moreover, we show that when no noise is present, this algorithm can be extended to the purely data-driven case where all previous guarantees hold and the need for a model is fully replaced by past-trajectory data. We show that the amount of data needed for our synthesis problem is independent of the size of the global system. Lastly, we explore the potential of DLMPC for hardware accelerated implementation in GPU by exploiting the fact that the structure of the DLMPC problem captures some of the limitations of GPU computations. In all algorithmic and theoretical results presented in this thesis, only local information exchange is necessary, and computational complexity is independent of the global system size. DLMPC is the first MPC algorithm that allows for the scalable, efficient and data-driven computation and implementation of distributed closed-loop control policies and enjoys theoretical guarantees.</summary></entry><entry><title type="html">Global performance guarantees for localized model predictive control</title><link href="http://localhost:4000/publications/2023/05/01/DLMPC-Global-Optimality.html" rel="alternate" type="text/html" title="Global performance guarantees for localized model predictive control" /><published>2023-05-01T00:00:00+02:00</published><updated>2023-05-01T00:00:00+02:00</updated><id>http://localhost:4000/publications/2023/05/01/DLMPC-Global-Optimality</id><content type="html" xml:base="http://localhost:4000/publications/2023/05/01/DLMPC-Global-Optimality.html">&lt;p&gt;Recent advances in model predictive control (MPC) leverage local communication constraints to produce localized MPC algorithms whose complexities scale independently of total network size. However, no characterization is available regarding global performance, i.e. whether localized MPC (with communication constraints) performs just as well as global MPC (no communication constraints). In this paper, we provide analysis and guarantees on global performance of localized MPC – in particular, we derive sufficient conditions for optimal global performance in the presence of local communication constraints. We also present an algorithm to determine the communication structure for a given system that will preserve performance while minimizing computational complexity. The effectiveness of the algorithm is verified in simulations, and additional relationships between network properties and performance-preserving communication constraints are characterized. A striking finding is that in a network of 121 coupled pendula, each node only needs to communicate with its immediate neighbors to preserve optimal global performance. Overall, this work offers theoretical understanding on the effect of local communication on global performance, and provides practitioners with the tools necessary to deploy localized model predictive control by establishing a rigorous method of selecting local communication constraints. This work also demonstrates – surprisingly – that the inclusion of severe communication constraints need not compromise global performance.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">Recent advances in model predictive control (MPC) leverage local communication constraints to produce localized MPC algorithms whose complexities scale independently of total network size. However, no characterization is available regarding global performance, i.e. whether localized MPC (with communication constraints) performs just as well as global MPC (no communication constraints). In this paper, we provide analysis and guarantees on global performance of localized MPC – in particular, we derive sufficient conditions for optimal global performance in the presence of local communication constraints. We also present an algorithm to determine the communication structure for a given system that will preserve performance while minimizing computational complexity. The effectiveness of the algorithm is verified in simulations, and additional relationships between network properties and performance-preserving communication constraints are characterized. A striking finding is that in a network of 121 coupled pendula, each node only needs to communicate with its immediate neighbors to preserve optimal global performance. Overall, this work offers theoretical understanding on the effect of local communication on global performance, and provides practitioners with the tools necessary to deploy localized model predictive control by establishing a rigorous method of selecting local communication constraints. This work also demonstrates – surprisingly – that the inclusion of severe communication constraints need not compromise global performance.</summary></entry><entry><title type="html">Distributed and Localized Model Predictive Control. Part II: Theoretical Guarantees</title><link href="http://localhost:4000/publications/2023/03/01/DLMPC-Part-II.html" rel="alternate" type="text/html" title="Distributed and Localized Model Predictive Control. Part II: Theoretical Guarantees" /><published>2023-03-01T00:00:00+01:00</published><updated>2023-03-01T00:00:00+01:00</updated><id>http://localhost:4000/publications/2023/03/01/DLMPC-Part-II</id><content type="html" xml:base="http://localhost:4000/publications/2023/03/01/DLMPC-Part-II.html">&lt;p&gt;Engineered cyberphysical systems are growing increasingly large and complex. These systems require scalable controllers that robustly satisfy state and input constraints in the presence of additive noise – such controllers should also be accompanied by theoretical guarantees on feasibility and stability. In our companion paper, we introduced Distributed and Localized Model Predictive Control (DLMPC) for large-scale linear systems; DLMPC is a scalable closed-loop MPC scheme in which subsystems need only exchange local information in order to synthesize and implement local controllers. In this paper, we provide recursive feasibility and asymptotic stability guarantees for DLMPC. We leverage the System Level Synthesis framework to express the maximal positive robust invariant set for the closed-loop system and its corresponding Lyapunov function, both in terms of the closed-loop system responses. We use the invariant set as the terminal set for DLMPC, and show that this guarantees feasibility with minimal conservatism. We use the Lyapunov function as the terminal cost, and show that this guarantees stability. We provide fully distributed and localized algorithms to compute the terminal set offline, and also provide necessary additions to the online DLMPC algorithm to accommodate coupled terminal constraint and cost. In all algorithms, only local information exchanges are necessary, and computational complexity is independent of the global system size – we demonstrate this analytically and experimentally. This is the first distributed MPC approach that provides minimally conservative yet fully distributed guarantees for recursive feasibility and asymptotic stability, for both nominal and robust settings.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">Engineered cyberphysical systems are growing increasingly large and complex. These systems require scalable controllers that robustly satisfy state and input constraints in the presence of additive noise – such controllers should also be accompanied by theoretical guarantees on feasibility and stability. In our companion paper, we introduced Distributed and Localized Model Predictive Control (DLMPC) for large-scale linear systems; DLMPC is a scalable closed-loop MPC scheme in which subsystems need only exchange local information in order to synthesize and implement local controllers. In this paper, we provide recursive feasibility and asymptotic stability guarantees for DLMPC. We leverage the System Level Synthesis framework to express the maximal positive robust invariant set for the closed-loop system and its corresponding Lyapunov function, both in terms of the closed-loop system responses. We use the invariant set as the terminal set for DLMPC, and show that this guarantees feasibility with minimal conservatism. We use the Lyapunov function as the terminal cost, and show that this guarantees stability. We provide fully distributed and localized algorithms to compute the terminal set offline, and also provide necessary additions to the online DLMPC algorithm to accommodate coupled terminal constraint and cost. In all algorithms, only local information exchanges are necessary, and computational complexity is independent of the global system size – we demonstrate this analytically and experimentally. This is the first distributed MPC approach that provides minimally conservative yet fully distributed guarantees for recursive feasibility and asymptotic stability, for both nominal and robust settings.</summary></entry><entry><title type="html">Distributed and Localized Model Predictive Control. Part I: Synthesis and Implementation</title><link href="http://localhost:4000/publications/2023/03/01/DLMPC-Part-I.html" rel="alternate" type="text/html" title="Distributed and Localized Model Predictive Control. Part I: Synthesis and Implementation" /><published>2023-03-01T00:00:00+01:00</published><updated>2023-03-01T00:00:00+01:00</updated><id>http://localhost:4000/publications/2023/03/01/DLMPC-Part-I</id><content type="html" xml:base="http://localhost:4000/publications/2023/03/01/DLMPC-Part-I.html">&lt;p&gt;The increasing presence of large-scale distributed systems highlights the need for scalable control strategies where only local communication is required. Moreover, in safety-critical systems it is imperative that such control strategies handle constraints in the presence of disturbances. In response to this need, we present the Distributed and Localized Model Predictive Control (DLMPC) algorithm for large-scale linear systems. DLMPC is a distributed closed-loop model predictive control (MPC) scheme wherein only local state and model information needs to be exchanged between subsystems for the computation and implementation of control actions. We use the System Level Synthesis (SLS) framework to reformulate the centralized MPC problem, and show that this allows us to naturally impose localized communication constraints between sub-controllers. The structure of the resulting problem can be exploited to develop an Alternating Direction Method of Multipliers (ADMM) based algorithm that allows for distributed and localized computation of closed-loop control policies. We demonstrate that computational complexity of the subproblems solved by each subsystem in DLMPC is independent of the size of the global system. To the best of our knowledge, DLMPC is the first MPC algorithm that allows for the scalable distributed computation as well as implementation of distributed closed-loop control policies, and seemingly deals with additive disturbances. In our companion paper, we show that this approach enjoys recursive feasibility and asymptotic stability.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">The increasing presence of large-scale distributed systems highlights the need for scalable control strategies where only local communication is required. Moreover, in safety-critical systems it is imperative that such control strategies handle constraints in the presence of disturbances. In response to this need, we present the Distributed and Localized Model Predictive Control (DLMPC) algorithm for large-scale linear systems. DLMPC is a distributed closed-loop model predictive control (MPC) scheme wherein only local state and model information needs to be exchanged between subsystems for the computation and implementation of control actions. We use the System Level Synthesis (SLS) framework to reformulate the centralized MPC problem, and show that this allows us to naturally impose localized communication constraints between sub-controllers. The structure of the resulting problem can be exploited to develop an Alternating Direction Method of Multipliers (ADMM) based algorithm that allows for distributed and localized computation of closed-loop control policies. We demonstrate that computational complexity of the subproblems solved by each subsystem in DLMPC is independent of the size of the global system. To the best of our knowledge, DLMPC is the first MPC algorithm that allows for the scalable distributed computation as well as implementation of distributed closed-loop control policies, and seemingly deals with additive disturbances. In our companion paper, we show that this approach enjoys recursive feasibility and asymptotic stability.</summary></entry><entry><title type="html">Effective GPU Parallelization of Distributed and Localized Model Predictive Control</title><link href="http://localhost:4000/publications/2022/06/01/DLMPC-GPU.html" rel="alternate" type="text/html" title="Effective GPU Parallelization of Distributed and Localized Model Predictive Control" /><published>2022-06-01T00:00:00+02:00</published><updated>2022-06-01T00:00:00+02:00</updated><id>http://localhost:4000/publications/2022/06/01/DLMPC-GPU</id><content type="html" xml:base="http://localhost:4000/publications/2022/06/01/DLMPC-GPU.html">&lt;p&gt;To effectively control large-scale distributed systems online, model predictive control (MPC) has to swiftly solve the underlying high-dimensional optimization. There are multiple techniques applied to accelerate the solving process in the literature, mainly attributed to software-based algorithmic advancements and hardware-assisted computation enhancements. However, those methods focus on arithmetic accelerations and overlook the benefits of the underlying system’s structure. In particular, the existing decoupled software-hardware algorithm design that naively parallelizes the arithmetic operations by the hardware does not tackle the hardware overheads such as CPU-GPU and thread-to-thread communications in a principled manner. Also, the advantages of parallelizable subproblem decomposition in distributed MPC are not well recognized and exploited. As a result, we have not reached the full potential of hardware acceleration for MPC. In this paper, we explore those opportunities by leveraging GPU to parallelize the distributed and localized MPC (DLMPC) algorithm. We exploit the locality constraints embedded in the DLMPC formulation to reduce the hardware-intrinsic communication overheads. Our parallel implementation achieves up to 50x faster runtime than its CPU counterparts under various parameters. Furthermore, we find that the locality-aware GPU parallelization could halve the optimization runtime comparing to the naive acceleration. Overall, our results demonstrate the performance gains brought by software-hardware co-design with the information exchange structure in mind.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">To effectively control large-scale distributed systems online, model predictive control (MPC) has to swiftly solve the underlying high-dimensional optimization. There are multiple techniques applied to accelerate the solving process in the literature, mainly attributed to software-based algorithmic advancements and hardware-assisted computation enhancements. However, those methods focus on arithmetic accelerations and overlook the benefits of the underlying system’s structure. In particular, the existing decoupled software-hardware algorithm design that naively parallelizes the arithmetic operations by the hardware does not tackle the hardware overheads such as CPU-GPU and thread-to-thread communications in a principled manner. Also, the advantages of parallelizable subproblem decomposition in distributed MPC are not well recognized and exploited. As a result, we have not reached the full potential of hardware acceleration for MPC. In this paper, we explore those opportunities by leveraging GPU to parallelize the distributed and localized MPC (DLMPC) algorithm. We exploit the locality constraints embedded in the DLMPC formulation to reduce the hardware-intrinsic communication overheads. Our parallel implementation achieves up to 50x faster runtime than its CPU counterparts under various parameters. Furthermore, we find that the locality-aware GPU parallelization could halve the optimization runtime comparing to the naive acceleration. Overall, our results demonstrate the performance gains brought by software-hardware co-design with the information exchange structure in mind.</summary></entry><entry><title type="html">Data-driven Distributed and Localized Model Predictive Control</title><link href="http://localhost:4000/publications/2022/04/01/D3LMPC.html" rel="alternate" type="text/html" title="Data-driven Distributed and Localized Model Predictive Control" /><published>2022-04-01T00:00:00+02:00</published><updated>2022-04-01T00:00:00+02:00</updated><id>http://localhost:4000/publications/2022/04/01/D3LMPC</id><content type="html" xml:base="http://localhost:4000/publications/2022/04/01/D3LMPC.html">&lt;p&gt;Motivated by large-scale but computationally constrained settings, e.g., the Internet of Things, we present a novel data-driven distributed control algorithm that is synthesized directly from trajectory data. Our method, data-driven Distributed and Localized Model Predictive Control (D3LMPC), builds upon the data-driven System Level Synthesis (SLS) framework, which allows one to parameterize \emph{closed-loop} system responses directly from collected open-loop trajectories. The resulting model-predictive controller can be implemented with distributed computation and only local information sharing. By imposing locality constraints on the system response, we show that the amount of data needed for our synthesis problem is independent of the size of the global system. Moreover, we show that our algorithm enjoys theoretical guarantees for recursive feasibility and asymptotic stability. Finally, we also demonstrate the optimality and scalability of our algorithm in a simulation experiment.&lt;/p&gt;</content><author><name></name></author><category term="publications" /><summary type="html">Motivated by large-scale but computationally constrained settings, e.g., the Internet of Things, we present a novel data-driven distributed control algorithm that is synthesized directly from trajectory data. Our method, data-driven Distributed and Localized Model Predictive Control (D3LMPC), builds upon the data-driven System Level Synthesis (SLS) framework, which allows one to parameterize \emph{closed-loop} system responses directly from collected open-loop trajectories. The resulting model-predictive controller can be implemented with distributed computation and only local information sharing. By imposing locality constraints on the system response, we show that the amount of data needed for our synthesis problem is independent of the size of the global system. Moreover, we show that our algorithm enjoys theoretical guarantees for recursive feasibility and asymptotic stability. Finally, we also demonstrate the optimality and scalability of our algorithm in a simulation experiment.</summary></entry></feed>